# OptimizaciÃ³n de Modelos de ClasificaciÃ³n para Dispositivos MÃ³viles con Recursos Limitados

> Trabajo Fin de MÃ¡ster (VIU, 2025). InvestigaciÃ³n aplicada para equilibrar **precisiÃ³n y eficiencia** en clasificaciÃ³n de imÃ¡genes ejecutada **on-device** en mÃ³viles y sistemas embebidos.



## ğŸ“Œ DescripciÃ³n
Este proyecto evalÃºa tÃ©cnicas de optimizaciÃ³n para llevar modelos de **aprendizaje profundo** a dispositivos con **memoria, cÃ³mputo y energÃ­a limitados**. Se compara un **Teacher** de alta capacidad (**Vision Transformer â€“ ViT Base**) frente a un **Student** eficiente (**MobileNetV3 Small**), entrenado en modo clÃ¡sico y con **Knowledge Distillation (KD)**.  
El estudio se realiza sobre **Food-101** (101 clases, >100k imÃ¡genes), un escenario multiclase exigente y representativo para despliegue mÃ³vil



## ğŸ¯ Objetivos
- Investigar la viabilidad de clasificaciÃ³n multiclase **on-device** manteniendo precisiÃ³n competitiva.
- Entrenar un **Teacher (ViT Base)** como referencia y un **Student (MobileNetV3 Small)** en dos variantes: **clÃ¡sico** y **con KD**.
- Comparar **precisiÃ³n**, **tamaÃ±o del modelo**, **latencia** (proyecciÃ³n a mÃ³vil) y **uso de memoria**.
- Demostrar que **KD** mejora la **generalizaciÃ³n** del Student manteniendo un tamaÃ±o reducido (â‰¤10 MB; ideal â‰¤5 MB).



## âš™ï¸ MetodologÃ­a
- **Dataset**: [Food-101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/)  
- **Modelos**:
  - **Teacher**: ViT Base (gran capacidad, guÃ­a del conocimiento).
  - **Student**: MobileNetV3 Small (eficiente para mÃ³viles).
- **Entrenamientos**:
  1) Student **clÃ¡sico**.  
  2) Student **con KD** (logits del Teacher con temperatura T y mezcla Î±).
- **EvaluaciÃ³n**:
  - MÃ©tricas de clasificaciÃ³n (Accuracy, F1 macro), **matriz de confusiÃ³n** y anÃ¡lisis por clase.
  - **TamaÃ±o del modelo** (MB) y **latencia** (mediciÃ³n en PC + proyecciÃ³n a mÃ³vil por gama).
  - DiscusiÃ³n de compromisos **precisiÃ³n â†” eficiencia** para despliegue real.



## ğŸ“Š Resultados principales

| Modelo                         | Rol      | TamaÃ±o aprox. | Accuracy test | Macro F1 | Hallazgos clave |
|--------------------------------|----------|---------------|---------------|----------|-----------------|
| **ViT Base**                   | Teacher  | ~327 MB       | **0.97**      | **0.97** | Modelo de referencia con altÃ­sima precisiÃ³n. Sin embargo, su gran tamaÃ±o y coste computacional lo hacen inviable para mÃ³viles. |
| **MobileNetV3 Small**          | Student  | ~6.3 MB       | **0.73**      | **0.73** | Modelo ligero y eficiente, pero con claras limitaciones de generalizaciÃ³n en un escenario multiclase complejo como Food-101. |
| **MobileNetV3 Small + KD**     | Student  | ~6.3 MB       | **0.90**      | **0.89** | La Knowledge Distillation mejora sustancialmente el rendimiento del Student, alcanzando un nivel cercano al Teacher con tamaÃ±o reducido y latencias bajas. |

> Resumen: **KD logra un salto del 73% al 90% en accuracy**, validando su eficacia para optimizar modelos ligeros sin incrementar el tamaÃ±o, lo que lo hace adecuado para **dispositivos mÃ³viles de gama media y baja**.

## ğŸ“Œ Conclusiones

- **ViT Base (Teacher)**: ofrece la mayor precisiÃ³n (97%), pero su tamaÃ±o (327 MB) y latencia lo hacen inviable en mÃ³viles.  
- **MobileNetV3 Student clÃ¡sico**: ligero (6 MB) y rÃ¡pido, pero con baja generalizaciÃ³n (73% de accuracy).  
- **MobileNetV3 Student + KD**: logra un equilibrio ideal (90% accuracy, tamaÃ±o reducido y baja latencia), validando la **Knowledge Distillation** como tÃ©cnica clave para **optimizar modelos ligeros en dispositivos con recursos limitados**.  

En conclusiÃ³n, el modelo **MobileNetV3 con KD** es la opciÃ³n mÃ¡s adecuada para **despliegue real en mÃ³viles**, combinando eficiencia y precisiÃ³n sin comprometer memoria ni tiempo de inferencia.  


## ğŸ“– Referencias
- Hinton, G., Vinyals, O., & Dean, J. (2015). *Distilling the Knowledge in a Neural Network*.  
- Dosovitskiy, A., et al. (2020). *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)*.  
- Howard, A., et al. (2019). *Searching for MobileNetV3*.  
- Zong, X., Zhang, Y., Wang, L., & Lin, S. (2023). *Edge AI Benchmarking of MobileNetV3 on Smartphones*. *Journal of Systems Architecture*.  


## ğŸ“œ Licencia
Este proyecto se distribuye bajo la licencia MIT.  
Consulta el archivo [LICENSE](LICENSE) para mÃ¡s detalles.  


## âœ‰ï¸ Contacto
Autor: **Luis Guaman**  
Repositorio: [TFM_OPTIMIZACION_MODELOS_CLASIFICACION_DISP_MOVILES](https://github.com/gluishs/TFM_OPTIMIZACION_MODELOS_CLASIFICACION_DISP_MOVILES)

## ğŸ§ª Reproducibilidad

### 1) Requisitos
- Python 3.10+
- PyTorch + torchvision
- timm, scikit-learn, numpy, matplotlib, tqdm, yaml
- 
## ğŸš€ Uso del repositorio

Este repositorio **no estÃ¡ orientado a instalaciÃ³n como paquete**, sino como proyecto acadÃ©mico/documental del TFM.  
Su propÃ³sito es **explorar, reproducir y analizar** entrenamientos y resultados.  

- Para revisar los experimentos â†’ abrir los notebooks en `notebooks/`.  
- Para ver modelos ya entrenados â†’ carpeta `models/`.  
- Para consultar resultados de mÃ©tricas y grÃ¡ficas â†’ carpeta `results/`.  
- Para revisar cÃ³digo auxiliar y funciones â†’ carpeta `src/`.


## ğŸ“‚ Estructura de directorios

```bash
â”œâ”€â”€ history/                  # Historiales de entrenamiento (curvas, logs, mÃ©tricas)
â”œâ”€â”€ models/                   # Modelos entrenados (.pth)
â”œâ”€â”€ notebooks/                # Jupyter Notebooks con el desarrollo del proyecto
â”œâ”€â”€ results/                  # Resultados de evaluaciÃ³n y comparativas
â”‚   â”œâ”€â”€ vit_base/             # Resultados del modelo Teacher (ViT Base)
â”‚   â”œâ”€â”€ student_classic/      # Resultados del modelo Student clÃ¡sico (MobileNetV3 Small)
â”‚   â”œâ”€â”€ student_kd/           # Resultados del modelo Student con Knowledge Distillation
â”‚   â””â”€â”€ comparison/           # Comparativas globales entre modelos
â”œâ”€â”€ src/                      # CÃ³digo auxiliar y scripts de soporte
â””â”€â”€ splits_food101_80_15_5.json  # DivisiÃ³n del dataset Food-101 (train/val/test)

